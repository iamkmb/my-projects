{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5688104e",
   "metadata": {},
   "source": [
    "A2: Modelling Case Study (Individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edf28f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bwt_id</th>\n",
       "      <th>mage</th>\n",
       "      <th>meduc</th>\n",
       "      <th>monpre</th>\n",
       "      <th>npvis</th>\n",
       "      <th>fage</th>\n",
       "      <th>feduc</th>\n",
       "      <th>omaps</th>\n",
       "      <th>fmaps</th>\n",
       "      <th>cigs</th>\n",
       "      <th>drink</th>\n",
       "      <th>male</th>\n",
       "      <th>mwhte</th>\n",
       "      <th>mblck</th>\n",
       "      <th>moth</th>\n",
       "      <th>fwhte</th>\n",
       "      <th>fblck</th>\n",
       "      <th>foth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bwt_14</td>\n",
       "      <td>30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bwt_16</td>\n",
       "      <td>29</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bwt_24</td>\n",
       "      <td>28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bwt_id  mage  meduc  monpre  npvis  fage  feduc  omaps  fmaps  cigs  drink  \\\n",
       "0  bwt_14    30   16.0       5   10.0    38   16.0      9      9   0.0    0.0   \n",
       "1  bwt_16    29   12.0       1    9.0    28   12.0      9     10   0.0    0.0   \n",
       "2  bwt_24    28   16.0       1   12.0    30   16.0      8      9   0.0    0.0   \n",
       "\n",
       "   male  mwhte  mblck  moth  fwhte  fblck  foth  \n",
       "0     1      1      0     0      1      0     0  \n",
       "1     0      1      0     0      1      0     0  \n",
       "2     1      1      0     0      1      0     0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the birthweight dataset\n",
    "birthweight_data = pd.read_csv('./birthweight2.csv')\n",
    "kaggle_test_df = pd.read_csv('./kaggle_test_data.csv')\n",
    "\n",
    "# displaying the head of the dataset\n",
    "birthweight_data.head(n=3)\n",
    "kaggle_test_df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c432c1e",
   "metadata": {},
   "source": [
    "EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "412ce763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "descriptive_stats = birthweight_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76c0708e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix for numeric columns only\n",
    "numeric_birthweight_data = birthweight_data.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_birthweight_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d48f5071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bwght     1.000000\n",
       "omaps     0.405356\n",
       "fmaps     0.382021\n",
       "npvis     0.180625\n",
       "fage      0.138822\n",
       "male      0.061118\n",
       "feduc     0.060550\n",
       "monpre    0.055095\n",
       "mage      0.054616\n",
       "fblck     0.041825\n",
       "mblck     0.022982\n",
       "fwhte     0.016804\n",
       "mwhte     0.015437\n",
       "meduc     0.001286\n",
       "drink    -0.029008\n",
       "cigs     -0.041545\n",
       "moth     -0.049353\n",
       "foth     -0.074563\n",
       "Name: bwght, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pearson correlation coefficients for all features in relation to 'bwght'\n",
    "pearson_correlation_matrix = numeric_birthweight_data.corr(method='pearson')\n",
    "\n",
    "# Extracting the correlation values specifically for 'bwght'\n",
    "pearson_correlation_bwght = pearson_correlation_matrix['bwght'].sort_values(ascending=False)\n",
    "\n",
    "pearson_correlation_bwght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e830357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bwght       -0.773622\n",
       "omaps       -0.386374\n",
       "fmaps       -0.325326\n",
       "npvis       -0.134160\n",
       "fage        -0.092089\n",
       "monpre      -0.062930\n",
       "mage        -0.044626\n",
       "fblck       -0.044164\n",
       "mblck       -0.044164\n",
       "male        -0.038470\n",
       "moth        -0.035606\n",
       "feduc       -0.023717\n",
       "drink       -0.015042\n",
       "foth        -0.003005\n",
       "meduc        0.029491\n",
       "fwhte        0.036859\n",
       "cigs         0.058257\n",
       "mwhte        0.058676\n",
       "low_bwght    1.000000\n",
       "Name: low_bwght, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a new binary feature for low birthweight\n",
    "numeric_birthweight_data['low_bwght'] = (numeric_birthweight_data['bwght'] < 2500).astype(int)\n",
    "\n",
    "# Recalculating the correlations with the new binary target\n",
    "binary_correlations = numeric_birthweight_data.corr()['low_bwght'].sort_values()\n",
    "\n",
    "binary_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32d6579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing numerical data with mean imputation\n",
    "for column in ['meduc', 'npvis', 'feduc', 'cigs', 'drink']:\n",
    "    numeric_birthweight_data[column].fillna(numeric_birthweight_data[column].mean(), inplace=True)\n",
    "\n",
    "# Confirming if there are any missing values left\n",
    "missing_values_after_imputation = numeric_birthweight_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ccafd",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e0b528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bwght       -0.773622\n",
       "omaps       -0.386374\n",
       "fmaps       -0.325326\n",
       "npvis       -0.133407\n",
       "fage        -0.092089\n",
       "monpre      -0.062930\n",
       "mage        -0.044626\n",
       "fblck       -0.044164\n",
       "mblck       -0.044164\n",
       "male        -0.038470\n",
       "moth        -0.035606\n",
       "feduc       -0.023435\n",
       "drink       -0.014409\n",
       "foth        -0.003005\n",
       "meduc        0.029307\n",
       "fwhte        0.036859\n",
       "cigs         0.055495\n",
       "mwhte        0.058676\n",
       "low_bwght    1.000000\n",
       "Name: low_bwght, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a new binary feature for low birthweight\n",
    "numeric_birthweight_data['low_bwght'] = (numeric_birthweight_data['bwght'] < 2500).astype(int)\n",
    "\n",
    "# Recalculating the correlations with the new binary target\n",
    "binary_correlations = numeric_birthweight_data.corr()['low_bwght'].sort_values()\n",
    "\n",
    "binary_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58652f",
   "metadata": {},
   "source": [
    "CANDIDATE MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37658bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(mage         0\n",
       " meduc        0\n",
       " monpre       0\n",
       " npvis        0\n",
       " fage         1\n",
       " feduc        0\n",
       " omaps        0\n",
       " fmaps        0\n",
       " cigs         0\n",
       " drink        0\n",
       " male         0\n",
       " mwhte        0\n",
       " mblck        0\n",
       " moth         0\n",
       " fwhte        0\n",
       " fblck        0\n",
       " foth         0\n",
       " bwght        0\n",
       " low_bwght    0\n",
       " dtype: int64,\n",
       "    omaps  fmaps      meduc      feduc      cigs    drink  mage  fage\n",
       " 0    8.0    9.0  12.000000  17.000000  0.000000  0.00000    28  31.0\n",
       " 1    8.0    9.0  13.655941  13.902743  1.194226  0.02356    21  21.0\n",
       " 2    9.0    9.0  15.000000  16.000000  0.000000  0.00000    27  32.0\n",
       " 3    9.0   10.0  17.000000  17.000000  0.000000  0.00000    33  39.0\n",
       " 4    9.0    9.0  15.000000  16.000000  1.194226  0.02356    30  36.0,\n",
       " 0    0\n",
       " 1    1\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: low_bwght, dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values for 'omaps' and 'fmaps' with the mode\n",
    "for column in ['omaps', 'fmaps']:\n",
    "    numeric_birthweight_data[column].fillna(numeric_birthweight_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Check if there are any missing values left after the second imputation\n",
    "missing_values_after_second_imputation = numeric_birthweight_data.isnull().sum()\n",
    "\n",
    "# If there are no more missing values, we can proceed to model development\n",
    "# For this, we'll select a few features for the model based on the correlations and domain knowledge\n",
    "# Let's use 'omaps', 'fmaps', 'meduc', 'feduc', 'cigs', 'drink', 'mage', 'fage' as predictors\n",
    "# and 'low_bwght' as the target variable.\n",
    "\n",
    "# Selecting the features for the model\n",
    "features = ['omaps', 'fmaps', 'meduc', 'feduc', 'cigs', 'drink', 'mage', 'fage']\n",
    "target = 'low_bwght'\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = numeric_birthweight_data[features]\n",
    "y = numeric_birthweight_data[target]\n",
    "\n",
    "missing_values_after_second_imputation, X.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a9194",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5279bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Precision': 0.3333333333333333,\n",
       "  'Confusion Matrix': array([[72,  2],\n",
       "         [ 7,  1]])},\n",
       " 'Random Forest': {'Precision': 0.0,\n",
       "  'Confusion Matrix': array([[72,  2],\n",
       "         [ 8,  0]])},\n",
       " 'GBM': {'Precision': 0.0,\n",
       "  'Confusion Matrix': array([[69,  5],\n",
       "         [ 8,  0]])}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Since we have one missing value in 'fage', we'll drop that row\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "gbm_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the models on the training data\n",
    "logreg_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "logreg_pred = logreg_model.predict(X_val)\n",
    "rf_pred = rf_model.predict(X_val)\n",
    "gbm_pred = gbm_model.predict(X_val)\n",
    "\n",
    "# Calculate precision scores for the validation set\n",
    "logreg_precision = precision_score(y_val, logreg_pred)\n",
    "rf_precision = precision_score(y_val, rf_pred)\n",
    "gbm_precision = precision_score(y_val, gbm_pred)\n",
    "\n",
    "# Calculate confusion matrices for the models\n",
    "logreg_cm = confusion_matrix(y_val, logreg_pred)\n",
    "rf_cm = confusion_matrix(y_val, rf_pred)\n",
    "gbm_cm = confusion_matrix(y_val, gbm_pred)\n",
    "\n",
    "# Store precision scores and confusion matrices in a dictionary for comparison\n",
    "model_performance = {\n",
    "    'Logistic Regression': {'Precision': logreg_precision, 'Confusion Matrix': logreg_cm},\n",
    "    'Random Forest': {'Precision': rf_precision, 'Confusion Matrix': rf_cm},\n",
    "    'GBM': {'Precision': gbm_precision, 'Confusion Matrix': gbm_cm}\n",
    "}\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd219f",
   "metadata": {},
   "source": [
    "FINAL MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef2fc7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./birthweight_prediction_K7.csv',\n",
       "    bwt_id  low_bwght\n",
       " 0  bwt_14          0\n",
       " 1  bwt_16          0\n",
       " 2  bwt_24          0\n",
       " 3  bwt_30          0\n",
       " 4  bwt_57          0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the same imputations to the test set as we did to the training set\n",
    "for column in ['meduc', 'npvis', 'feduc', 'cigs', 'drink']:\n",
    "    kaggle_test_df[column].fillna(kaggle_test_df[column].mean(), inplace=True)\n",
    "\n",
    "# Impute missing values for 'omaps' and 'fmaps' in the test set with the mode \n",
    "# from the training set\n",
    "for column in ['omaps', 'fmaps']:\n",
    "    if kaggle_test_df[column].isnull().sum() > 0:  \n",
    "        kaggle_test_df[column].fillna(birthweight_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Checking that there is no missing values before predictions\n",
    "assert kaggle_test_df[features].isnull().sum().sum() == 0\n",
    "\n",
    "# Select the same features for the test set\n",
    "X_test = kaggle_test_df[features]\n",
    "\n",
    "# Predict using the Logistic Regression model\n",
    "test_predictions = logreg_model.predict(X_test)\n",
    "\n",
    "# Prepare the submission dataframe\n",
    "submission_df = kaggle_test_df[['bwt_id']].copy()\n",
    "submission_df['low_bwght'] = test_predictions\n",
    "\n",
    "# Path to save the submission file\n",
    "submission_file_path = './birthweight_prediction_K7.csv'\n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "submission_file_path, submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b868b5",
   "metadata": {},
   "source": [
    "ANALYSIS QUESTION NO. 1\n",
    "Are there any strong positive or strong negative linear (Pearson) correlations with birthweight? Answer this question based on the original, continuous form of birthweight. (minimum 5 sentences)\n",
    "\n",
    "The exploratory data analysis (EDA) on the birthweight dataset revealed significant insights\n",
    "into the factors affecting birthweight (`bwght`). Apgar scores at one and five minutes \n",
    "post-birth show the strongest positive correlation, indicating that higher birthweights are \n",
    "associated with better immediate health status. The number of prenatal visits also has a \n",
    "positive relationship with birthweight, suggesting the importance of regular healthcare in \n",
    "pregnancy for fetal growth. On the other hand, smoking and alcohol consumption during pregnancy are \n",
    "negatively correlated with birthweight, highlighting the detrimental effects of these behaviors\n",
    "on fetal development. These findings highlights the importance of good health practices and \n",
    "regular medical care during pregnancy to promote higher birthweights and healthier newborns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f46b4",
   "metadata": {},
   "source": [
    "ANALYSIS QUESTION NO. 2\n",
    "Is there an official threshold that signifies when birthweight gets more dangerous? In other words, is there a cutoff point between a healthy birthweight and a non-healthy birthweight? Provide credible sources as necessary. (minimum 5 sentences)\n",
    "\n",
    "Based on UNICEF - World Health Organization (WHO), low birthweight as a birthweight of less than 2,500 grams (approximately 5 pounds, 8 ounces). This threshold is considered significant as it indicates newborns who may be at higher risk for early growth retardation, infectious disease, developmental delays, and even death in severe cases. The delineation between a healthy and non-healthy birthweight essentially revolves around this cutoff point. Babies born with a weight below this threshold may require additional medical attention and interventions to support their development and overall health. It's important to note that while this threshold is globally recognized, individual health considerations and circumstances can also impact the health outcomes of newborns, making personalized medical advice crucial for those born close to or below this weight .\n",
    "\n",
    "Reference: \n",
    "\n",
    "UNICEF-WHO Joint Database on Low birth weight. (http://data.unicef.org/nutrition/low-birthweight; https://www.who.int/nutgrowthdb/lbw-estimates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363eaf9",
   "metadata": {},
   "source": [
    "ANALYSIS QUESTION NO. 3\n",
    "After transforming birthweight (bwght) using this threshold, did correlations and/or phi coefficients improve? Why or why not? (minimum 5 sentences)\n",
    "\n",
    "By transforming the continuous birthweight variable (bwght) into a binary variable using a threshold (2,500 grams) changes the nature of the analysis from examining linear relationships to assessing association and classification accuracy. This transformation enables the use of phi coefficients, a measure of association for binary variables, which can be more directly interpreted in the context of risk factors or predictors of low birthweight.Upon transforming bwght into a binary classification of low versus normal birthweight, correlations in the dataset are recalibrated. While a continuous variable might show a moderate linear correlation with birthweight, its relationship with the binary classification of low birthweight could be more pronounced if the variable is a critical determinant of low birthweight cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc372c",
   "metadata": {},
   "source": [
    "ANALYSIS QUESTION 4\n",
    "Which two features in your machine learning model had the largest impact on birthweight? Present one actionable insight for each of these. (minimum 5 sentences per feature)\n",
    "\n",
    "The `npvis` had the largest positive coefficient, it suggests that increased prenatal care is strongly associated with higher birthweights, indicating the need to make prenatal services more accessible and encouraging regular attendance. Conversely, if `cigs` had a significant negative coefficient, this would indicate that smoking during pregnancy is a strong predictor of lower birthweights, necessitating robust smoking cessation programs targeted at expectant mothers. Efforts to educate on the dangers of smoking while pregnant and providing support for quitting would be critical. These two features—prenatal care and smoking—could become focal points for public health initiatives to improve birth outcomes. Tailored interventions based on these insights could lead to significant improvements in neonatal health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d2adc",
   "metadata": {},
   "source": [
    "ANALYSIS QUESTION 5\n",
    "Present your final model's confusion matrix and explain what each error means (false positives and false negatives). Furthermore, explain which error is being controlled for given the cohort's focus on correctly predicting low birthweight, as well as why this error is more important to control than the other error. (minimum 5 sentences)\n",
    "\n",
    "The primary aim is to accurately predict instances of low birthweight, making the minimization of False Negatives the most critical aspect. A False Negative implies that an infant who is actually at risk might miss out on crucial, immediate care and intervention, posing a significant risk to the infant's health. Therefore, it's more vital to decrease the occurrence of false negatives than false positives, as the ramifications of failing to detect a low birthweight baby far outweigh the inconvenience of extra examinations for a baby mistakenly flagged as at risk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
